

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="">
  <meta name="author" content="Dongys">
  <meta name="keywords" content="">
  
  <title>Kafka源码解析-日志对象的常见操作 - Blog</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"dong-ys.github.io","root":"/","version":"1.8.11","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 6.2.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Dongys's Blog</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('https://picture.zwc365.com/getbing.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="Kafka源码解析-日志对象的常见操作">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2022-08-31 15:20" pubdate>
        2022年8月31日 下午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      7.5k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      104
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Kafka源码解析-日志对象的常见操作</h1>
            
            <div class="markdown-body">
              <h1 id="Kafka源码解析-日志对象的常见操作"><a href="#Kafka源码解析-日志对象的常见操作" class="headerlink" title="Kafka源码解析-日志对象的常见操作"></a>Kafka源码解析-日志对象的常见操作</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Log类用于管理服务端日志相关的各种操作， 这里把Log 的常见操作分为 4 大部分：</p>
<ul>
<li>日志段管理：滚动生成新日志段、组织并管理分区下的所有日志段等</li>
<li>关键位移值管理：日志定义了很多重要的位移值，如LogStartOffset、LEO等</li>
<li>读写操作：进行日志的读写</li>
<li>高水位操作管理：定义了对于高水位值的各种操作，包括更新和读取</li>
</ul>
<h2 id="高水位管理操作"><a href="#高水位管理操作" class="headerlink" title="高水位管理操作"></a>高水位管理操作</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>源码中日志对象定义高水位的语句只有一行</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-meta">@volatile</span> <span class="hljs-keyword">private</span> <span class="hljs-keyword">var</span> highWatermarkMetadata: <span class="hljs-type">LogOffsetMetadata</span> = <span class="hljs-type">LogOffsetMetadata</span>(logStartOffset)<br></code></pre></td></tr></table></figure>

<p>这行定义体现了两个要点：</p>
<ul>
<li><p><strong>高水位值是易变的</strong>，因为多个线程可能同时读取它，因此需要设置成volatile，保证内存可见性。另外，由于高水位值可能被多个线程同时修改，因此源码使用 Java Monitor 锁来确保并发修改的线程安全。</p>
</li>
<li><p><strong>高水位值的初始值是 LogStartOffset</strong>，每个 Log 对象都会维护一个 LogStartOffset 值，当首次构建高水位时，它会被赋值成 LogStartOffset。接下来看一下 LogOffsetMetadata 类的定义：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">case</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LogOffsetMetadata</span>(<span class="hljs-params">messageOffset: <span class="hljs-type">Long</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                             segmentBaseOffset: <span class="hljs-type">Long</span> = <span class="hljs-type">Log</span>.<span class="hljs-type">UnknownOffset</span>,</span></span><br><span class="hljs-params"><span class="hljs-class">                             relativePositionInSegment: <span class="hljs-type">Int</span> = <span class="hljs-type">LogOffsetMetadata</span>.<span class="hljs-type">UnknownFilePosition</span></span>)</span><br></code></pre></td></tr></table></figure>

<p>里面保存了三个重要变量：</p>
<ul>
<li>messageOffset：消息位移值，这个变量的值就是指高水位值</li>
<li>segmentBaseOffset：保存该位移值所属日志段的起始位移，用来判断两条消息是否处于同一日志段上</li>
<li>relativePositionInSegment：保存该位移值所在日志段的物理磁盘位置</li>
</ul>
</li>
</ul>
<h3 id="高水位值的获取和设置"><a href="#高水位值的获取和设置" class="headerlink" title="高水位值的获取和设置"></a>高水位值的获取和设置</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-comment">// 获取高水位值</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">highWatermark</span></span>: <span class="hljs-type">Long</span> = highWatermarkMetadata.messageOffset<br><br><span class="hljs-comment">// 读取高水位对象</span><br><span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fetchHighWatermarkMetadata</span></span>: <span class="hljs-type">LogOffsetMetadata</span> = &#123;<br>  <span class="hljs-comment">// 读取时确保日志不能被关闭</span><br>  checkIfMemoryMappedBufferClosed()<br><br>  <span class="hljs-comment">// 保存当前高水位值到本地变量，避免多线程修改</span><br>  <span class="hljs-keyword">val</span> offsetMetadata = highWatermarkMetadata<br>  <span class="hljs-keyword">if</span> (offsetMetadata.messageOffsetOnly) &#123;<br>    <span class="hljs-comment">// 没有获取到完整的高水位元数据</span><br>    lock.synchronized &#123;<br>      <span class="hljs-comment">// 从日志中找到对应的高水位元数据</span><br>      <span class="hljs-keyword">val</span> fullOffset = convertToOffsetMetadataOrThrow(highWatermark)<br>      updateHighWatermarkMetadata(fullOffset)<br>      fullOffset<br>    &#125;<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    offsetMetadata<br>  &#125;<br>&#125;<br><br><span class="hljs-comment">// 设置高水位值</span><br><span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">updateHighWatermarkMetadata</span></span>(newHighWatermark: <span class="hljs-type">LogOffsetMetadata</span>): <span class="hljs-type">Unit</span> = &#123;<br>  <span class="hljs-keyword">if</span> (newHighWatermark.messageOffset &lt; <span class="hljs-number">0</span>)<br>  <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">IllegalArgumentException</span>(<span class="hljs-string">&quot;High watermark offset should be non-negative&quot;</span>)<br><br>  <span class="hljs-comment">// 保护Log对象修改的Monitor锁</span><br>  lock synchronized &#123;<br>    <span class="hljs-keyword">if</span> (newHighWatermark.messageOffset &lt; highWatermarkMetadata.messageOffset) &#123;<br>      warn(<span class="hljs-string">s&quot;Non-monotonic update of high watermark from <span class="hljs-subst">$highWatermarkMetadata</span> to <span class="hljs-subst">$newHighWatermark</span>&quot;</span>)<br>    &#125;<br><br>    highWatermarkMetadata = newHighWatermark<br>    producerStateManager.onHighWatermarkUpdated(newHighWatermark.messageOffset)<br>    maybeIncrementFirstUnstableOffset()<br>  &#125;<br>  trace(<span class="hljs-string">s&quot;Setting high watermark <span class="hljs-subst">$newHighWatermark</span>&quot;</span>)<br>&#125;<br></code></pre></td></tr></table></figure>

<p><strong>fetchHighWatermarkMetadata</strong> 方法不仅仅是获取高水位值，还要获取高水位的其他元数据信息，即日志段起始位移和物理位置信息。</p>
<h3 id="更新高水位值"><a href="#更新高水位值" class="headerlink" title="更新高水位值"></a>更新高水位值</h3><p>除此之外，源码还定义了两个更新高水位值的方法：<strong>updateHighWatermark</strong> 和<strong>maybeIncrementHighWatermark</strong>。从名字上来看，前者是一定要更新高水位值的，而后者是可能会更新也可能不会。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">updateHighWatermark</span></span>(highWatermarkMetadata: <span class="hljs-type">LogOffsetMetadata</span>): <span class="hljs-type">Long</span> = &#123;<br>  <span class="hljs-keyword">val</span> endOffsetMetadata = logEndOffsetMetadata<br>  <span class="hljs-keyword">val</span> newHighWatermarkMetadata = <span class="hljs-keyword">if</span> (highWatermarkMetadata.messageOffset &lt; logStartOffset) &#123;<br>    <span class="hljs-type">LogOffsetMetadata</span>(logStartOffset)<br>  &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (highWatermarkMetadata.messageOffset &gt;= endOffsetMetadata.messageOffset) &#123;<br>    endOffsetMetadata<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    highWatermarkMetadata<br>  &#125;<br><br>  <span class="hljs-comment">// 调用Setter方法来更新高水位值</span><br>  updateHighWatermarkMetadata(newHighWatermarkMetadata)<br>  newHighWatermarkMetadata.messageOffset<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">maybeIncrementHighWatermark</span></span>(newHighWatermark: <span class="hljs-type">LogOffsetMetadata</span>): <span class="hljs-type">Option</span>[<span class="hljs-type">LogOffsetMetadata</span>] = &#123;<br>  <span class="hljs-comment">// 新高水位值不能越过Log End Offset</span><br>  <span class="hljs-keyword">if</span> (newHighWatermark.messageOffset &gt; logEndOffset)<br>  <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">IllegalArgumentException</span>(<span class="hljs-string">s&quot;High watermark <span class="hljs-subst">$newHighWatermark</span> update exceeds current &quot;</span> +<br>                                     <span class="hljs-string">s&quot;log end offset <span class="hljs-subst">$logEndOffsetMetadata</span>&quot;</span>)<br><br>  lock.synchronized &#123;<br>    <span class="hljs-keyword">val</span> oldHighWatermark = fetchHighWatermarkMetadata<br><br>    <span class="hljs-comment">// Ensure that the high watermark increases monotonically. We also update the high watermark when the new</span><br>    <span class="hljs-comment">// offset metadata is on a newer segment, which occurs whenever the log is rolled to a new segment.</span><br>    <span class="hljs-comment">// 新高水位值要比老高水位值大以维持单调增加特性，否则就不做更新!</span><br>    <span class="hljs-comment">// 另外，如果新高水位值在新日志段上，也可执行更新高水位操作</span><br>    <span class="hljs-keyword">if</span> (oldHighWatermark.messageOffset &lt; newHighWatermark.messageOffset ||<br>        (oldHighWatermark.messageOffset == newHighWatermark.messageOffset &amp;&amp; oldHighWatermark.onOlderSegment(newHighWatermark))) &#123;<br>      updateHighWatermarkMetadata(newHighWatermark)<br>      <span class="hljs-type">Some</span>(oldHighWatermark)<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      <span class="hljs-type">None</span><br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>这两个方法有着不同的用途。<strong>updateHighWatermark</strong> 方法用在 Follower 副本从 Leader 副本获取到消息后更新高水位值。一旦拿到新的消息，就必须要更新高水位值。而 <strong>maybeIncrementHighWatermark</strong> 方法，主要是用来更新 Leader 副本的高水位值，由于Leader副本高水位值的更新是由条件的，因为它可能需要等到其他 Follower 副本同步的进度，因此某些情况下可能不会更新。</p>
<h2 id="日志段管理"><a href="#日志段管理" class="headerlink" title="日志段管理"></a>日志段管理</h2><p>日志是日志段的容器，那它究竟是如何承担起容器一职的呢？</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">private</span> <span class="hljs-keyword">val</span> segments: <span class="hljs-type">ConcurrentNavigableMap</span>[java.lang.<span class="hljs-type">Long</span>, <span class="hljs-type">LogSegment</span>] = <span class="hljs-keyword">new</span> <span class="hljs-type">ConcurrentSkipListMap</span>[java.lang.<span class="hljs-type">Long</span>, <span class="hljs-type">LogSegment</span>]<br></code></pre></td></tr></table></figure>

<p>可以看到，源码使用 Java 的 <strong>ConcurrentSkipListMap</strong> 类来保存所有日志段对象。ConcurrentSkipListMap 有 2 个明显的优势。</p>
<ul>
<li><p><strong>它是线程安全的</strong>，这样 Kafka 源码不需要自行确保日志段操作过程中的线程安全；</p>
</li>
<li><p><strong>它是键值（Key）可排序的 Map</strong>。Kafka 将每个日志段的起始位移值作为 Key，这样一来，我们就能够很方便地根据所有日志段的起始位移值对它们进行排序和比较，同时还能快速地找到与给定位移值相近的前后两个日志段。</p>
</li>
</ul>
<p>接下来看一下日志段的增删改查操作</p>
<h3 id="增加"><a href="#增加" class="headerlink" title="增加"></a>增加</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-meta">@threadsafe</span><br><span class="hljs-keyword">private</span>[log] <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">addSegment</span></span>(segment: <span class="hljs-type">LogSegment</span>): <span class="hljs-type">LogSegment</span> = <span class="hljs-keyword">this</span>.segments.put(segment.baseOffset, segment)<br></code></pre></td></tr></table></figure>

<p>Log 对象中定义了添加日志段对象的方法：<strong>addSegment</strong>，就是调用 Map 的 put 方法将给定的日志段对象添加到 segments 中。</p>
<h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><p>删除操作相对来说复杂一点。Kafka 有很多留存策略，包括基于时间维度的、基于空间维度的和基于 Log Start Offset 维度的。留存策略本质上就是<strong>根据一定的规则决定哪些日志段可以删除</strong>。</p>
<p>从源码角度来看，Log 中控制删除操作的总入口是 <strong>deleteOldSegments 无参方法</strong>：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">deleteOldSegments</span></span>(): <span class="hljs-type">Int</span> = &#123;<br>  <span class="hljs-keyword">if</span> (config.delete) &#123;<br>    deleteRetentionMsBreachedSegments() + deleteRetentionSizeBreachedSegments() + deleteLogStartOffsetBreachedSegments()<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    deleteLogStartOffsetBreachedSegments()<br>  &#125;<br>&#125;<br><br><span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">deleteRetentionMsBreachedSegments</span></span>(): <span class="hljs-type">Int</span> = &#123;<br>  <span class="hljs-keyword">if</span> (config.retentionMs &lt; <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>  <span class="hljs-keyword">val</span> startMs = time.milliseconds<br><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">shouldDelete</span></span>(segment: <span class="hljs-type">LogSegment</span>, nextSegmentOpt: <span class="hljs-type">Option</span>[<span class="hljs-type">LogSegment</span>]): <span class="hljs-type">Boolean</span> = &#123;<br>    startMs - segment.largestTimestamp &gt; config.retentionMs<br>  &#125;<br><br>  deleteOldSegments(shouldDelete, <span class="hljs-type">RetentionMsBreach</span>)<br>&#125;<br><br><span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">deleteRetentionSizeBreachedSegments</span></span>(): <span class="hljs-type">Int</span> = &#123;<br>  <span class="hljs-keyword">if</span> (config.retentionSize &lt; <span class="hljs-number">0</span> || size &lt; config.retentionSize) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>  <span class="hljs-keyword">var</span> diff = size - config.retentionSize<br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">shouldDelete</span></span>(segment: <span class="hljs-type">LogSegment</span>, nextSegmentOpt: <span class="hljs-type">Option</span>[<span class="hljs-type">LogSegment</span>]): <span class="hljs-type">Boolean</span> = &#123;<br>    <span class="hljs-keyword">if</span> (diff - segment.size &gt;= <span class="hljs-number">0</span>) &#123;<br>      diff -= segment.size<br>      <span class="hljs-literal">true</span><br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      <span class="hljs-literal">false</span><br>    &#125;<br>  &#125;<br><br>  deleteOldSegments(shouldDelete, <span class="hljs-type">RetentionSizeBreach</span>)<br>&#125;<br><br><span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">deleteLogStartOffsetBreachedSegments</span></span>(): <span class="hljs-type">Int</span> = &#123;<br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">shouldDelete</span></span>(segment: <span class="hljs-type">LogSegment</span>, nextSegmentOpt: <span class="hljs-type">Option</span>[<span class="hljs-type">LogSegment</span>]): <span class="hljs-type">Boolean</span> = &#123;<br>    nextSegmentOpt.exists(_.baseOffset &lt;= logStartOffset)<br>  &#125;<br><br>  deleteOldSegments(shouldDelete, <span class="hljs-type">StartOffsetBreach</span>)<br>&#125;<br></code></pre></td></tr></table></figure>

<p>代码中的 <strong>deleteRetentionMsBreachedSegments</strong>、<strong>deleteRetentionSizeBreachedSegments</strong> 和<strong>deleteLogStartOffsetBreachedSegments</strong> 分别对应于上面的那 3 个策略。</p>
<p>上面 3 个留存策略方法底层都会调用<strong>带参数版本的 deleteOldSegments 方法</strong>，而这个方法又相继调用了 <strong>deletableSegments</strong> 和<strong>deleteSegments</strong> 方法。下面，我们来深入学习下这 3 个方法的代码。</p>
<p>首先是带参数版本的 <strong>deleteOldSegments</strong> 方法：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">deleteOldSegments</span></span>(predicate: (<span class="hljs-type">LogSegment</span>, <span class="hljs-type">Option</span>[<span class="hljs-type">LogSegment</span>]) =&gt; <span class="hljs-type">Boolean</span>,<br>                              reason: <span class="hljs-type">SegmentDeletionReason</span>): <span class="hljs-type">Int</span> = &#123;<br>  lock synchronized &#123;<br>    <span class="hljs-keyword">val</span> deletable = deletableSegments(predicate)<br>    <span class="hljs-keyword">if</span> (deletable.nonEmpty)<br>      deleteSegments(deletable, reason)<br>    <span class="hljs-keyword">else</span><br>      <span class="hljs-number">0</span><br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>该方法只有两个步骤：</p>
<ol>
<li><p>使用传入的函数计算哪些日志段对象能够被删除；</p>
</li>
<li><p>调用 deleteSegments 方法删除这些日志段。</p>
</li>
</ol>
<p>接下来是 deletableSegments 方法：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">deletableSegments</span></span>(predicate: (<span class="hljs-type">LogSegment</span>, <span class="hljs-type">Option</span>[<span class="hljs-type">LogSegment</span>]) =&gt; <span class="hljs-type">Boolean</span>): <span class="hljs-type">Iterable</span>[<span class="hljs-type">LogSegment</span>] = &#123;<br>  <span class="hljs-keyword">if</span> (segments.isEmpty) &#123;<br>    <span class="hljs-type">Seq</span>.empty<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    <span class="hljs-keyword">val</span> deletable = <span class="hljs-type">ArrayBuffer</span>.empty[<span class="hljs-type">LogSegment</span>]<br>    <span class="hljs-keyword">var</span> segmentEntry = segments.firstEntry<br>    <span class="hljs-comment">// 从具有最小起始位移值的日志段对象开始遍历，直到满足以下条件之一便停止遍历: </span><br>    <span class="hljs-comment">// 1. 测定条件函数predicate = false</span><br>    <span class="hljs-comment">// 2. 扫描到包含Log对象高水位值所在的日志段对象</span><br>    <span class="hljs-comment">// 3. 最新的日志段对象不包含任何消息</span><br>    <span class="hljs-comment">// 最新日志段对象是segments中Key值最大对应的那个日志段，也就是我们常说的Active Segment</span><br>    <span class="hljs-comment">// 在遍历过程中，同时不满足以上3个条件的所有日志段都是可以被删除的!</span><br>    <span class="hljs-keyword">while</span> (segmentEntry != <span class="hljs-literal">null</span>) &#123;<br>      <span class="hljs-keyword">val</span> segment = segmentEntry.getValue<br>      <span class="hljs-keyword">val</span> nextSegmentEntry = segments.higherEntry(segmentEntry.getKey)<br>      <span class="hljs-keyword">val</span> (nextSegment, upperBoundOffset, isLastSegmentAndEmpty) = <span class="hljs-keyword">if</span> (nextSegmentEntry != <span class="hljs-literal">null</span>)<br>        (nextSegmentEntry.getValue, nextSegmentEntry.getValue.baseOffset, <span class="hljs-literal">false</span>)<br>      <span class="hljs-keyword">else</span><br>        (<span class="hljs-literal">null</span>, logEndOffset, segment.size == <span class="hljs-number">0</span>)<br><br>      <span class="hljs-keyword">if</span> (highWatermark &gt;= upperBoundOffset &amp;&amp; predicate(segment, <span class="hljs-type">Option</span>(nextSegment)) &amp;&amp; !isLastSegmentAndEmpty) &#123;<br>        deletable += segment<br>        segmentEntry = nextSegmentEntry<br>      &#125; <span class="hljs-keyword">else</span> &#123;<br>        segmentEntry = <span class="hljs-literal">null</span><br>      &#125;<br>    &#125;<br>    deletable<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>最后是 deleteSegments 方法，这个方法执行真正的日志段删除操作。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">deleteSegments</span></span>(deletable: <span class="hljs-type">Iterable</span>[<span class="hljs-type">LogSegment</span>], reason: <span class="hljs-type">SegmentDeletionReason</span>): <span class="hljs-type">Int</span> = &#123;<br>  maybeHandleIOException(<span class="hljs-string">s&quot;Error while deleting segments for <span class="hljs-subst">$topicPartition</span> in dir <span class="hljs-subst">$&#123;dir.getParent&#125;</span>&quot;</span>) &#123;<br>    <span class="hljs-keyword">val</span> numToDelete = deletable.size<br>    <span class="hljs-keyword">if</span> (numToDelete &gt; <span class="hljs-number">0</span>) &#123;<br>      <span class="hljs-comment">// we must always have at least one segment, so if we are going to delete all the segments, create a new one first</span><br>      <span class="hljs-comment">// 不允许删除所有日志段对象。如果一定要做，先创建出一个新的来，然后再把前面N个删掉</span><br>      <span class="hljs-keyword">if</span> (segments.size == numToDelete)<br>        roll()<br>      lock synchronized &#123;<br>        checkIfMemoryMappedBufferClosed()<br>        <span class="hljs-comment">// remove the segments for lookups</span><br>        <span class="hljs-comment">// 删除给定的日志段对象以及底层的物理文件</span><br>        removeAndDeleteSegments(deletable, asyncDelete = <span class="hljs-literal">true</span>, reason)<br>        <span class="hljs-comment">// 尝试更新日志的Log Start Offset值</span><br>        maybeIncrementLogStartOffset(segments.firstEntry.getValue.baseOffset, <span class="hljs-type">SegmentDeletion</span>)<br>      &#125;<br>    &#125;<br>    numToDelete<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>LogStartOffset 值是整个 Log 对象对外可见消息的最小位移值。如果我们删除了日志段对象，很有可能对外可见消息的范围发生了变化，自然要看一下是否需要更新 LogStartOffset 值。这就是 deleteSegments 方法最后要更新 LogStartOffset 值的原因。</p>
<h3 id="修改"><a href="#修改" class="headerlink" title="修改"></a>修改</h3><p>说完了日志段删除，接下来我们来看如何修改日志段对象。其实，源码里面不涉及修改日志段对象，所谓的修改或更新也就是替换而已，用新的日志段对象替换老的日志段对象。</p>
<p>举个简单的例子。segments.put(1L, newSegment) 语句在没有 Key&#x3D;1 时是添加日志段，否则就是替换已有日志段。</p>
<h3 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h3><p>最后再说下查询日志段对象。源码中需要查询日志段对象的地方太多了，但主要都是利用了 ConcurrentSkipListMap 的现成方法。</p>
<ul>
<li><p>segments.firstEntry：获取第一个日志段对象；</p>
</li>
<li><p>segments.lastEntry：获取最后一个日志段对象，即 Active Segment；</p>
</li>
<li><p>segments.higherEntry：获取第一个起始位移值≥给定 Key 值的日志段对象；</p>
</li>
<li><p>segments.floorEntry：获取最后一个起始位移值≤给定 Key 值的日志段对象。</p>
</li>
</ul>
<h2 id="关键位移值管理"><a href="#关键位移值管理" class="headerlink" title="关键位移值管理"></a>关键位移值管理</h2><p>Log 对象维护了一些关键位移值数据，比如 Log Start Offset、LEO 等。下图可以更明显的体现这些位移值的区别和关联。</p>
<img src="/2022/08/31/Kafka%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-%E6%97%A5%E5%BF%97%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/image-20220831162333847.png" srcset="/img/loading.gif" lazyload class="" title="image-20220831162333847">

<p>注意这张图中位移值 15 的虚线方框。这揭示了一个重要的事实：<strong>Log 对象中的 LEO 永远指向下一条待插入消息</strong>，也就是说，LEO 值上面是没有消息的！源码中定义 LEO 的语句很简单：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-meta">@volatile</span> <span class="hljs-keyword">private</span> <span class="hljs-keyword">var</span> nextOffsetMetadata: <span class="hljs-type">LogOffsetMetadata</span> = _<br></code></pre></td></tr></table></figure>

<p>这里的 nextOffsetMetadata 就是我们所说的 LEO，它也是 LogOffsetMetadata 类型的对象。Log 对象初始化的时候，源码会加载所有日志段对象，并由此计算出当前 Log 的下一条消息位移值。之后，Log 对象将此位移值赋值给 LEO，代码片段如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs scala">locally &#123;<br>  <span class="hljs-comment">// create the log directory if it doesn&#x27;t exist</span><br>  <span class="hljs-comment">// 创建分区日志路径</span><br>  <span class="hljs-type">Files</span>.createDirectories(dir.toPath)<br><br>  <span class="hljs-comment">// 初始化Leader Epoch Cache</span><br>  initializeLeaderEpochCache()<br>  initializePartitionMetadata()<br><br>  <span class="hljs-comment">// 加载所有日志段对象</span><br>  <span class="hljs-keyword">val</span> nextOffset = loadSegments()<br><br>  <span class="hljs-comment">/* Calculate the offset of the next message */</span><br>  <span class="hljs-comment">// 更新nextOffsetMetadata 和 LogStartOffset</span><br>  nextOffsetMetadata = <span class="hljs-type">LogOffsetMetadata</span>(nextOffset, activeSegment.baseOffset, activeSegment.size)<br>  ...<br>&#125;<br></code></pre></td></tr></table></figure>

<p>代码中也单独定义了更新 LEO 的 updateLogEndOffset 方法：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">updateLogEndOffset</span></span>(offset: <span class="hljs-type">Long</span>): <span class="hljs-type">Unit</span> = &#123;<br>  nextOffsetMetadata = <span class="hljs-type">LogOffsetMetadata</span>(offset, activeSegment.baseOffset, activeSegment.size)<br><br>  <span class="hljs-comment">// Update the high watermark in case it has gotten ahead of the log end offset following a truncation</span><br>  <span class="hljs-comment">// or if a new segment has been rolled and the offset metadata needs to be updated.</span><br>  <span class="hljs-keyword">if</span> (highWatermark &gt;= offset) &#123;<br>    updateHighWatermarkMetadata(nextOffsetMetadata)<br>  &#125;<br><br>  <span class="hljs-keyword">if</span> (<span class="hljs-keyword">this</span>.recoveryPoint &gt; offset) &#123;<br>    <span class="hljs-keyword">this</span>.recoveryPoint = offset<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>如果在更新过程中发现新 LEO 值小于高水位值，那么 Kafka 还要更新高水位值，因为对于同一个 Log 对象而言，高水位值是不能越过 LEO 值的。</p>
<p>LEO 对象被更新的时机有 4 个：</p>
<ul>
<li><strong>Log 对象初始化时</strong>：当 Log 对象初始化时，我们必须要创建一个 LEO 对象，并对其进行初始化。</li>
<li><strong>写入新消息时</strong>：以上面的图为例，当不断向 Log 对象插入新消息时，LEO 值就像一个指针一样，需要不停地向右移动，也就是不断地增加。</li>
<li><strong>Log 对象发生日志切分（Log Roll）时</strong>：日志切分其实就是创建一个全新的日志段对象，并且关闭当前写入的日志段对象。这通常发生在当前日志段对象已满的时候。一旦发生日志切分，说明 Log 对象切换了 Active Segment，那么，LEO 中的起始位移值和段大小数据都要被更新。</li>
<li><strong>日志截断（Log Truncation）时</strong>：日志中的部分消息被删除了，自然可能导致 LEO 值发生变化，从而要更新 LEO 对象。</li>
</ul>
<p>接下来再看一下 LogStartOffset，就操作的流程和原理而言，源码管理 LogStartOffset 的方式要比 LEO 简单，因为 LogStartOffset 不是一个对象，它就是一个长整型的值而已。代码定义了专门的 updateLogStartOffset 方法来更新它：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">updateLogStartOffset</span></span>(offset: <span class="hljs-type">Long</span>): <span class="hljs-type">Unit</span> = &#123;<br>  logStartOffset = offset<br><br>  <span class="hljs-keyword">if</span> (highWatermark &lt; offset) &#123;<br>    updateHighWatermark(offset)<br>  &#125;<br><br>  <span class="hljs-keyword">if</span> (<span class="hljs-keyword">this</span>.recoveryPoint &lt; offset) &#123;<br>    <span class="hljs-keyword">this</span>.recoveryPoint = offset<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>LogStartOffset 的更新时机：</p>
<ul>
<li><p><strong>Log 对象初始化时</strong>：和 LEO 类似，Log 对象初始化时要给 Log Start Offset 赋值，一般是将第一个日志段的起始位移值赋值给它。</p>
</li>
<li><p><strong>日志截断时</strong>：同理，一旦日志中的部分消息被删除，可能会导致 Log Start Offset 发生变化，因此有必要更新该值。</p>
</li>
<li><p><strong>Follower 副本同步时</strong>：一旦 Leader 副本的 Log 对象的 Log Start Offset 值发生变化。为了维持和 Leader 副本的一致性，Follower 副本也需要尝试去更新该值。</p>
</li>
<li><p><strong>删除日志段时</strong>：这个和日志截断是类似的。凡是涉及消息删除的操作都有可能导致 LogStartOffset 值的变化。</p>
</li>
<li><p><strong>删除消息时</strong>：在 Kafka 中，删除消息就是通过抬高 Log Start Offset 值来实现的，因此，删除消息时必须要更新该值。</p>
</li>
</ul>
<h2 id="读写操作"><a href="#读写操作" class="headerlink" title="读写操作"></a>读写操作</h2><h3 id="写操作"><a href="#写操作" class="headerlink" title="写操作"></a>写操作</h3><p>日志写数据操作的相关方法共有三个，appendAsLeader、appendAsFollower、append，它们的关系如下：</p>
<img src="/2022/08/31/Kafka%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-%E6%97%A5%E5%BF%97%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/modb_20211012_163eb296-2b3f-11ec-94a3-fa163eb4f6be.png" srcset="/img/loading.gif" lazyload class="" title="img">

<p>appendAsLeader 是用于写 Leader 副本的，appendAsFollower 是用于 Follower 副本同步的。它们的底层都调用了 append 方法。</p>
<p>下图是 append 方法的执行流程：</p>
<img src="/2022/08/31/Kafka%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-%E6%97%A5%E5%BF%97%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/modb_20211012_15b6baf8-2b3f-11ec-94a3-fa163eb4f6be.png" srcset="/img/loading.gif" lazyload class="" title="img">

<p>append 代码如下，由于代码较长，通过注释的形式在代码中解释含义：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">append</span></span>(records: <span class="hljs-type">MemoryRecords</span>,<br>                   origin: <span class="hljs-type">AppendOrigin</span>,<br>                   interBrokerProtocolVersion: <span class="hljs-type">ApiVersion</span>,<br>                   validateAndAssignOffsets: <span class="hljs-type">Boolean</span>,<br>                   leaderEpoch: <span class="hljs-type">Int</span>,<br>                   ignoreRecordSize: <span class="hljs-type">Boolean</span>): <span class="hljs-type">LogAppendInfo</span> = &#123;<br>  <span class="hljs-comment">// We want to ensure the partition metadata file is written to the log dir before any log data is written to disk.</span><br>  <span class="hljs-comment">// This will ensure that any log data can be recovered with the correct topic ID in the case of failure.</span><br>  <span class="hljs-comment">// 步骤零：确保在将任何日志数据写入磁盘之前将分区元数据文件写入日志文件。这将确保在失败的情况下可以使用正确的topic ID 恢复任何日志数据。</span><br>  maybeFlushMetadataFile()<br><br>  <span class="hljs-comment">// 步骤一：消息校验，返回一个LogAppendInfo对象</span><br>  <span class="hljs-keyword">val</span> appendInfo = analyzeAndValidateRecords(records, origin, ignoreRecordSize, leaderEpoch)<br><br>  <span class="hljs-comment">// return if we have no valid messages or if this is a duplicate of the last appended entry</span><br>  <span class="hljs-comment">// 如果没有需要返回的数据，直接返回</span><br>  <span class="hljs-keyword">if</span> (appendInfo.shallowCount == <span class="hljs-number">0</span>) appendInfo<br>  <span class="hljs-keyword">else</span> &#123;<br><br>    <span class="hljs-comment">// trim any invalid bytes or partial messages before appending it to the on-disk log</span><br>    <span class="hljs-comment">// 步骤二：消息格式规整，即删除无效格式消息或无效字节</span><br>    <span class="hljs-keyword">var</span> validRecords = trimInvalidBytes(records, appendInfo)<br><br>    <span class="hljs-comment">// they are valid, insert them in the log</span><br>    lock synchronized &#123;<br>      maybeHandleIOException(<span class="hljs-string">s&quot;Error while appending records to <span class="hljs-subst">$topicPartition</span> in dir <span class="hljs-subst">$&#123;dir.getParent&#125;</span>&quot;</span>) &#123;<br>        <span class="hljs-comment">// 确保log对象未关闭</span><br>        checkIfMemoryMappedBufferClosed()<br>        <span class="hljs-keyword">if</span> (validateAndAssignOffsets) &#123;<br>          <span class="hljs-comment">// assign offsets to the message set</span><br>          <span class="hljs-comment">// 第3步：使用当前LEO值作为待写入消息集合中第一条消息的位移值</span><br>          <span class="hljs-keyword">val</span> offset = <span class="hljs-keyword">new</span> <span class="hljs-type">LongRef</span>(nextOffsetMetadata.messageOffset)<br>          appendInfo.firstOffset = <span class="hljs-type">Some</span>(<span class="hljs-type">LogOffsetMetadata</span>(offset.value))<br>          <span class="hljs-keyword">val</span> now = time.milliseconds<br>          <span class="hljs-keyword">val</span> validateAndOffsetAssignResult = <span class="hljs-keyword">try</span> &#123;<br>            <span class="hljs-type">LogValidator</span>.validateMessagesAndAssignOffsets(validRecords,<br>              topicPartition,<br>              offset,<br>              time,<br>              now,<br>              appendInfo.sourceCodec,<br>              appendInfo.targetCodec,<br>              config.compact,<br>              config.messageFormatVersion.recordVersion.value,<br>              config.messageTimestampType,<br>              config.messageTimestampDifferenceMaxMs,<br>              leaderEpoch,<br>              origin,<br>              interBrokerProtocolVersion,<br>              brokerTopicStats)<br>          &#125; <span class="hljs-keyword">catch</span> &#123;<br>            <span class="hljs-keyword">case</span> e: <span class="hljs-type">IOException</span> =&gt;<br>              <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">KafkaException</span>(<span class="hljs-string">s&quot;Error validating messages while appending to log <span class="hljs-subst">$name</span>&quot;</span>, e)<br>          &#125;<br>          <span class="hljs-comment">// 更新校验结果</span><br>          validRecords = validateAndOffsetAssignResult.validatedRecords<br>          appendInfo.maxTimestamp = validateAndOffsetAssignResult.maxTimestamp<br>          appendInfo.offsetOfMaxTimestamp = validateAndOffsetAssignResult.shallowOffsetOfMaxTimestamp<br>          appendInfo.lastOffset = offset.value - <span class="hljs-number">1</span><br>          appendInfo.recordConversionStats = validateAndOffsetAssignResult.recordConversionStats<br>          <span class="hljs-keyword">if</span> (config.messageTimestampType == <span class="hljs-type">TimestampType</span>.<span class="hljs-type">LOG_APPEND_TIME</span>)<br>            appendInfo.logAppendTime = now<br><br>          <span class="hljs-comment">// re-validate message sizes if there&#x27;s a possibility that they have changed (due to re-compression or message</span><br>          <span class="hljs-comment">// format conversion)</span><br>          <span class="hljs-comment">// 步骤四：验证消息，确保消息大小不超限</span><br>          <span class="hljs-keyword">if</span> (!ignoreRecordSize &amp;&amp; validateAndOffsetAssignResult.messageSizeMaybeChanged) &#123;<br>            validRecords.batches.forEach &#123; batch =&gt;<br>              <span class="hljs-keyword">if</span> (batch.sizeInBytes &gt; config.maxMessageSize) &#123;<br>                <span class="hljs-comment">// we record the original message set size instead of the trimmed size</span><br>                <span class="hljs-comment">// to be consistent with pre-compression bytesRejectedRate recording</span><br>                brokerTopicStats.topicStats(topicPartition.topic).bytesRejectedRate.mark(records.sizeInBytes)<br>                brokerTopicStats.allTopicsStats.bytesRejectedRate.mark(records.sizeInBytes)<br>                <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">RecordTooLargeException</span>(<span class="hljs-string">s&quot;Message batch size is <span class="hljs-subst">$&#123;batch.sizeInBytes&#125;</span> bytes in append to&quot;</span> +<br>                  <span class="hljs-string">s&quot;partition <span class="hljs-subst">$topicPartition</span> which exceeds the maximum configured size of <span class="hljs-subst">$&#123;config.maxMessageSize&#125;</span>.&quot;</span>)<br>              &#125;<br>            &#125;<br>          &#125;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>          <span class="hljs-comment">// we are taking the offsets we are given</span><br>          <span class="hljs-comment">// 直接使用给定的位移值，无需分配</span><br>          <span class="hljs-keyword">if</span> (!appendInfo.offsetsMonotonic) &#123;<br>            <span class="hljs-comment">// 确保消息位移值的单调递增</span><br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">OffsetsOutOfOrderException</span>(<span class="hljs-string">s&quot;Out of order offsets found in append to <span class="hljs-subst">$topicPartition</span>: &quot;</span> +<br>              records.records.asScala.map(_.offset))<br>          &#125;<br><br>          <span class="hljs-comment">// 如果消息集中的最大偏移量都小于当前LEO，则说明没有要更新的消息</span><br>          <span class="hljs-keyword">if</span> (appendInfo.firstOrLastOffsetOfFirstBatch &lt; nextOffsetMetadata.messageOffset) &#123;<br>            <span class="hljs-comment">// we may still be able to recover if the log is empty</span><br>            <span class="hljs-comment">// one example: fetching from log start offset on the leader which is not batch aligned,</span><br>            <span class="hljs-comment">// which may happen as a result of AdminClient#deleteRecords()</span><br>            <span class="hljs-comment">// 更新firstOffset，由于默认为None，所有这里取：records.batches.asScala.head.baseOffset()，即第一个批次的起始偏移量</span><br>            <span class="hljs-keyword">val</span> firstOffset = appendInfo.firstOffset <span class="hljs-keyword">match</span> &#123;<br>              <span class="hljs-keyword">case</span> <span class="hljs-type">Some</span>(offsetMetadata) =&gt; offsetMetadata.messageOffset<br>              <span class="hljs-keyword">case</span> <span class="hljs-type">None</span> =&gt; records.batches.asScala.head.baseOffset()<br>            &#125;<br><br>            <span class="hljs-keyword">val</span> firstOrLast = <span class="hljs-keyword">if</span> (appendInfo.firstOffset.isDefined) <span class="hljs-string">&quot;First offset&quot;</span> <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;Last offset of the first batch&quot;</span><br>            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">UnexpectedAppendOffsetException</span>(<br>              <span class="hljs-string">s&quot;Unexpected offset in append to <span class="hljs-subst">$topicPartition</span>. <span class="hljs-subst">$firstOrLast</span> &quot;</span> +<br>                <span class="hljs-string">s&quot;<span class="hljs-subst">$&#123;appendInfo.firstOrLastOffsetOfFirstBatch&#125;</span> is less than the next offset <span class="hljs-subst">$&#123;nextOffsetMetadata.messageOffset&#125;</span>. &quot;</span> +<br>                <span class="hljs-string">s&quot;First 10 offsets in append: <span class="hljs-subst">$&#123;records.records.asScala.take(10).map(_.offset)&#125;</span>, last offset in&quot;</span> +<br>                <span class="hljs-string">s&quot; append: <span class="hljs-subst">$&#123;appendInfo.lastOffset&#125;</span>. Log start offset = <span class="hljs-subst">$logStartOffset</span>&quot;</span>,<br>              firstOffset, appendInfo.lastOffset)<br>          &#125;<br>        &#125;<br><br>        <span class="hljs-comment">// update the epoch cache with the epoch stamped onto the message by the leader</span><br>        <span class="hljs-comment">// 步骤五：更新Leader Epoch缓存</span><br>        validRecords.batches.forEach &#123; batch =&gt;<br>          <span class="hljs-keyword">if</span> (batch.magic &gt;= <span class="hljs-type">RecordBatch</span>.<span class="hljs-type">MAGIC_VALUE_V2</span>) &#123;<br>            maybeAssignEpochStartOffset(batch.partitionLeaderEpoch, batch.baseOffset)<br>          &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-comment">// In partial upgrade scenarios, we may get a temporary regression to the message format. In</span><br>            <span class="hljs-comment">// order to ensure the safety of leader election, we clear the epoch cache so that we revert</span><br>            <span class="hljs-comment">// to truncation by high watermark after the next leader election.</span><br>            leaderEpochCache.filter(_.nonEmpty).foreach &#123; cache =&gt;<br>              warn(<span class="hljs-string">s&quot;Clearing leader epoch cache after unexpected append with message format v<span class="hljs-subst">$&#123;batch.magic&#125;</span>&quot;</span>)<br>              cache.clearAndFlush()<br>            &#125;<br>          &#125;<br>        &#125;<br><br>        <span class="hljs-comment">// check messages set size may be exceed config.segmentSize</span><br>        <span class="hljs-comment">// 步骤六：确保消息大小不超限，不超过一个Segment的大小，即1G</span><br>        <span class="hljs-keyword">if</span> (validRecords.sizeInBytes &gt; config.segmentSize) &#123;<br>          <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">RecordBatchTooLargeException</span>(<span class="hljs-string">s&quot;Message batch size is <span class="hljs-subst">$&#123;validRecords.sizeInBytes&#125;</span> bytes in append &quot;</span> +<br>            <span class="hljs-string">s&quot;to partition <span class="hljs-subst">$topicPartition</span>, which exceeds the maximum configured segment size of <span class="hljs-subst">$&#123;config.segmentSize&#125;</span>.&quot;</span>)<br>        &#125;<br><br>        <span class="hljs-comment">// maybe roll the log if this segment is full</span><br>        <span class="hljs-comment">// 步骤七：执行日志切分。当前日志段剩余容量可能无法容纳新消息集合，因此有必要创建一个新的日志段</span><br>        <span class="hljs-keyword">val</span> segment = maybeRoll(validRecords.sizeInBytes, appendInfo)<br><br>        <span class="hljs-keyword">val</span> logOffsetMetadata = <span class="hljs-type">LogOffsetMetadata</span>(<br>          messageOffset = appendInfo.firstOrLastOffsetOfFirstBatch,<br>          segmentBaseOffset = segment.baseOffset,<br>          relativePositionInSegment = segment.size)<br><br>        <span class="hljs-comment">// now that we have valid records, offsets assigned, and timestamps updated, we need to</span><br>        <span class="hljs-comment">// validate the idempotent/transactional state of the producers and collect some metadata</span><br>        <span class="hljs-comment">// 步骤八：验证事务状态</span><br>        <span class="hljs-keyword">val</span> (updatedProducers, completedTxns, maybeDuplicate) = analyzeAndValidateProducerState(<br>          logOffsetMetadata, validRecords, origin)<br><br>        maybeDuplicate <span class="hljs-keyword">match</span> &#123;<br>          <span class="hljs-keyword">case</span> <span class="hljs-type">Some</span>(duplicate) =&gt;<br>            appendInfo.firstOffset = <span class="hljs-type">Some</span>(<span class="hljs-type">LogOffsetMetadata</span>(duplicate.firstOffset))<br>            appendInfo.lastOffset = duplicate.lastOffset<br>            appendInfo.logAppendTime = duplicate.timestamp<br>            appendInfo.logStartOffset = logStartOffset<br>          <span class="hljs-keyword">case</span> <span class="hljs-type">None</span> =&gt;<br>            <span class="hljs-comment">// Before appending update the first offset metadata to include segment information</span><br>            appendInfo.firstOffset = appendInfo.firstOffset.map &#123; offsetMetadata =&gt;<br>              offsetMetadata.copy(segmentBaseOffset = segment.baseOffset, relativePositionInSegment = segment.size)<br>            &#125;<br><br>            <span class="hljs-comment">// 步骤九：执行真正的消息写入操作，主要调用日志段对象的append方法实现</span><br>            segment.append(largestOffset = appendInfo.lastOffset,<br>              largestTimestamp = appendInfo.maxTimestamp,<br>              shallowOffsetOfMaxTimestamp = appendInfo.offsetOfMaxTimestamp,<br>              records = validRecords)<br><br>            <span class="hljs-comment">// Increment the log end offset. We do this immediately after the append because a</span><br>            <span class="hljs-comment">// write to the transaction index below may fail and we want to ensure that the offsets</span><br>            <span class="hljs-comment">// of future appends still grow monotonically. The resulting transaction index inconsistency</span><br>            <span class="hljs-comment">// will be cleaned up after the log directory is recovered. Note that the end offset of the</span><br>            <span class="hljs-comment">// ProducerStateManager will not be updated and the last stable offset will not advance</span><br>            <span class="hljs-comment">// if the append to the transaction index fails.</span><br>            <span class="hljs-comment">// 步骤十：更新LEO对象，其中，LEO值是消息集合中最后一条消息位移值+1</span><br>            updateLogEndOffset(appendInfo.lastOffset + <span class="hljs-number">1</span>)<br><br>            <span class="hljs-comment">// update the producer state</span><br>            <span class="hljs-comment">// 步骤十一：更新事务状态</span><br>            updatedProducers.values.foreach(producerAppendInfo =&gt; producerStateManager.update(producerAppendInfo))<br><br>            <span class="hljs-comment">// update the transaction index with the true last stable offset. The last offset visible</span><br>            <span class="hljs-comment">// to consumers using READ_COMMITTED will be limited by this value and the high watermark.</span><br>            completedTxns.foreach &#123; completedTxn =&gt;<br>              <span class="hljs-keyword">val</span> lastStableOffset = producerStateManager.lastStableOffset(completedTxn)<br>              segment.updateTxnIndex(completedTxn, lastStableOffset)<br>              producerStateManager.completeTxn(completedTxn)<br>            &#125;<br><br>            <span class="hljs-comment">// always update the last producer id map offset so that the snapshot reflects the current offset</span><br>            <span class="hljs-comment">// even if there isn&#x27;t any idempotent data being written</span><br>            producerStateManager.updateMapEndOffset(appendInfo.lastOffset + <span class="hljs-number">1</span>)<br><br>            <span class="hljs-comment">// update the first unstable offset (which is used to compute LSO)</span><br>            maybeIncrementFirstUnstableOffset()<br><br>            trace(<span class="hljs-string">s&quot;Appended message set with last offset: <span class="hljs-subst">$&#123;appendInfo.lastOffset&#125;</span>, &quot;</span> +<br>              <span class="hljs-string">s&quot;first offset: <span class="hljs-subst">$&#123;appendInfo.firstOffset&#125;</span>, &quot;</span> +<br>              <span class="hljs-string">s&quot;next offset: <span class="hljs-subst">$&#123;nextOffsetMetadata.messageOffset&#125;</span>, &quot;</span> +<br>              <span class="hljs-string">s&quot;and messages: <span class="hljs-subst">$validRecords</span>&quot;</span>)<br><br>            <span class="hljs-comment">//是否需要手动落盘。一般情况下不需要设置Broker端参数log.flush.interval.messages</span><br>            <span class="hljs-comment">// 落盘操作交由操作系统来完成。但某些情况下，可以设置该参数来确保高可靠性</span><br>            <span class="hljs-keyword">if</span> (unflushedMessages &gt;= config.flushInterval) flush()<br>        &#125;<br>        <span class="hljs-comment">// 步骤十二：返回写入结果</span><br>        appendInfo<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>这里需要关注第一步，即 <strong>Kafka 如何校验消息</strong>，重点是看<strong>针对不同的消息格式版本，Kafka 是如何做校验的</strong>。</p>
<p>在说消息校验之前，需要先了解一下 LogAppendInfo 这个类，里面几乎保存了待写入消息集合的所有信息。</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">case</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LogAppendInfo</span>(<span class="hljs-params">var firstOffset: <span class="hljs-type">Option</span>[<span class="hljs-type">LogOffsetMetadata</span>], //消息集合中的第一个偏移量，只有消息版本小于<span class="hljs-type">V2</span>，且追加给follower副本时才有，如果是重复消息，则base offset 和 relative position都是未知的</span></span><br><span class="hljs-params"><span class="hljs-class">                         var lastOffset: <span class="hljs-type">Long</span>, //消息集合最后一条消息的位移</span></span><br><span class="hljs-params"><span class="hljs-class">                         var lastLeaderEpoch: <span class="hljs-type">Option</span>[<span class="hljs-type">Int</span>], //分区中与最后一个偏移量对应的leader epoch</span></span><br><span class="hljs-params"><span class="hljs-class">                         var maxTimestamp: <span class="hljs-type">Long</span>, 	//消息集合最大消息时间戳</span></span><br><span class="hljs-params"><span class="hljs-class">                         var offsetOfMaxTimestamp: <span class="hljs-type">Long</span>, //消息集合最大消息时间戳所属消息的偏移量</span></span><br><span class="hljs-params"><span class="hljs-class">                         var logAppendTime: <span class="hljs-type">Long</span>, //写入消息时间戳</span></span><br><span class="hljs-params"><span class="hljs-class">                         var logStartOffset: <span class="hljs-type">Long</span>, //消息集合首条消息的偏移量</span></span><br><span class="hljs-params"><span class="hljs-class">                         var recordConversionStats: <span class="hljs-type">RecordConversionStats</span>, //消息转换统计类，里面记录了执行了格式转换的消息数等数据</span></span><br><span class="hljs-params"><span class="hljs-class">                         sourceCodec: <span class="hljs-type">CompressionCodec</span>, //接收消息的压缩格式</span></span><br><span class="hljs-params"><span class="hljs-class">                         targetCodec: <span class="hljs-type">CompressionCodec</span>, //写入日志的压缩格式</span></span><br><span class="hljs-params"><span class="hljs-class">                         shallowCount: <span class="hljs-type">Int</span>, //消息批次数，每个消息批次下可能包含多条消息</span></span><br><span class="hljs-params"><span class="hljs-class">                         validBytes: <span class="hljs-type">Int</span>, //写入消息总字节数</span></span><br><span class="hljs-params"><span class="hljs-class">                         offsetsMonotonic: <span class="hljs-type">Boolean</span>, //消息位移值是否是单调递增的</span></span><br><span class="hljs-params"><span class="hljs-class">                         lastOffsetOfFirstBatch: <span class="hljs-type">Long</span>, //首个消息批次中最后一条消息的偏移量</span></span><br><span class="hljs-params"><span class="hljs-class">                         recordErrors: <span class="hljs-type">Seq</span>[<span class="hljs-type">RecordError</span>] = <span class="hljs-type">List</span>(</span>),</span><br>                         errorMessage: <span class="hljs-type">String</span> = <span class="hljs-literal">null</span>,<br>                         leaderHwChange: <span class="hljs-type">LeaderHwChange</span> = <span class="hljs-type">LeaderHwChange</span>.<span class="hljs-type">None</span>)<br></code></pre></td></tr></table></figure>

<p>analyzeAndValidateRecords 方法用来校验待写入的消息集合，然后将校验结果封装成LogAppendInfo对象返回，具体流程如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-keyword">private</span> <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">analyzeAndValidateRecords</span></span>(records: <span class="hljs-type">MemoryRecords</span>,<br>                                      origin: <span class="hljs-type">AppendOrigin</span>,<br>                                      ignoreRecordSize: <span class="hljs-type">Boolean</span>,<br>                                      leaderEpoch: <span class="hljs-type">Int</span>): <span class="hljs-type">LogAppendInfo</span> = &#123;<br>  <span class="hljs-keyword">var</span> shallowMessageCount = <span class="hljs-number">0</span><br>  <span class="hljs-keyword">var</span> validBytesCount = <span class="hljs-number">0</span><br>  <span class="hljs-keyword">var</span> firstOffset: <span class="hljs-type">Option</span>[<span class="hljs-type">LogOffsetMetadata</span>] = <span class="hljs-type">None</span><br>  <span class="hljs-keyword">var</span> lastOffset = <span class="hljs-number">-1</span>L<br>  <span class="hljs-keyword">var</span> lastLeaderEpoch = <span class="hljs-type">RecordBatch</span>.<span class="hljs-type">NO_PARTITION_LEADER_EPOCH</span><br>  <span class="hljs-keyword">var</span> sourceCodec: <span class="hljs-type">CompressionCodec</span> = <span class="hljs-type">NoCompressionCodec</span><br>  <span class="hljs-keyword">var</span> monotonic = <span class="hljs-literal">true</span><br>  <span class="hljs-keyword">var</span> maxTimestamp = <span class="hljs-type">RecordBatch</span>.<span class="hljs-type">NO_TIMESTAMP</span><br>  <span class="hljs-keyword">var</span> offsetOfMaxTimestamp = <span class="hljs-number">-1</span>L<br>  <span class="hljs-keyword">var</span> readFirstMessage = <span class="hljs-literal">false</span><br>  <span class="hljs-keyword">var</span> lastOffsetOfFirstBatch = <span class="hljs-number">-1</span>L<br><br>  records.batches.forEach &#123; batch =&gt;<br>    <span class="hljs-keyword">if</span> (origin == <span class="hljs-type">RaftLeader</span> &amp;&amp; batch.partitionLeaderEpoch != leaderEpoch) &#123;<br>      <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">InvalidRecordException</span>(<span class="hljs-string">&quot;Append from Raft leader did not set the batch epoch correctly&quot;</span>)<br>    &#125;<br>    <span class="hljs-comment">// we only validate V2 and higher to avoid potential compatibility issues with older clients</span><br>    <span class="hljs-comment">// 消息格式 Version 2的消息批次，起始位移值必须从0开始</span><br>    <span class="hljs-keyword">if</span> (batch.magic &gt;= <span class="hljs-type">RecordBatch</span>.<span class="hljs-type">MAGIC_VALUE_V2</span> &amp;&amp; origin == <span class="hljs-type">AppendOrigin</span>.<span class="hljs-type">Client</span> &amp;&amp; batch.baseOffset != <span class="hljs-number">0</span>)<br>      <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">InvalidRecordException</span>(<span class="hljs-string">s&quot;The baseOffset of the record batch in the append to <span class="hljs-subst">$topicPartition</span> should &quot;</span> +<br>        <span class="hljs-string">s&quot;be 0, but it is <span class="hljs-subst">$&#123;batch.baseOffset&#125;</span>&quot;</span>)<br><br>    <span class="hljs-comment">// update the first offset if on the first message. For magic versions older than 2, we use the last offset</span><br>    <span class="hljs-comment">// to avoid the need to decompress the data (the last offset can be obtained directly from the wrapper message).</span><br>    <span class="hljs-comment">// For magic version 2, we can get the first offset directly from the batch header.</span><br>    <span class="hljs-comment">// When appending to the leader, we will update LogAppendInfo.baseOffset with the correct value. In the follower</span><br>    <span class="hljs-comment">// case, validation will be more lenient.</span><br>    <span class="hljs-comment">// Also indicate whether we have the accurate first offset or not</span><br>    <span class="hljs-comment">// 只有第一个批次走这个分支</span><br>    <span class="hljs-keyword">if</span> (!readFirstMessage) &#123;<br>      <span class="hljs-keyword">if</span> (batch.magic &gt;= <span class="hljs-type">RecordBatch</span>.<span class="hljs-type">MAGIC_VALUE_V2</span>)<br>        firstOffset = <span class="hljs-type">Some</span>(<span class="hljs-type">LogOffsetMetadata</span>(batch.baseOffset))<br>      <span class="hljs-comment">//更新第一个批次的最大偏移量</span><br>      lastOffsetOfFirstBatch = batch.lastOffset<br>      readFirstMessage = <span class="hljs-literal">true</span><br>    &#125;<br><br>    <span class="hljs-comment">// check that offsets are monotonically increasing</span><br>    <span class="hljs-comment">// 如果当前批次的lastOffset小于等于上一个批次的lastOffset，说明上一个批次中有偏移量大于后面batch的消息</span><br>    <span class="hljs-comment">// 这违反了偏移量的单调递增性</span><br>    <span class="hljs-keyword">if</span> (lastOffset &gt;= batch.lastOffset)<br>      monotonic = <span class="hljs-literal">false</span><br><br>    <span class="hljs-comment">// update the last offset seen</span><br>    <span class="hljs-comment">// 更新lastOffset为当前批次的最后的偏移量</span><br>    lastOffset = batch.lastOffset<br>    lastLeaderEpoch = batch.partitionLeaderEpoch<br><br>    <span class="hljs-comment">// Check if the message sizes are valid.</span><br>    <span class="hljs-comment">// 判断批次的大小是否大于配置的最大消息大小：由 broker 端参数 max.message.bytes 配置，默认为：1000000 + Records.LOG_OVERHEAD(12)</span><br>    <span class="hljs-keyword">val</span> batchSize = batch.sizeInBytes<br>    <span class="hljs-keyword">if</span> (!ignoreRecordSize &amp;&amp; batchSize &gt; config.maxMessageSize) &#123;<br>      brokerTopicStats.topicStats(topicPartition.topic).bytesRejectedRate.mark(records.sizeInBytes)<br>      brokerTopicStats.allTopicsStats.bytesRejectedRate.mark(records.sizeInBytes)<br>      <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">RecordTooLargeException</span>(<span class="hljs-string">s&quot;The record batch size in the append to <span class="hljs-subst">$topicPartition</span> is <span class="hljs-subst">$batchSize</span> bytes &quot;</span> +<br>        <span class="hljs-string">s&quot;which exceeds the maximum configured value of <span class="hljs-subst">$&#123;config.maxMessageSize&#125;</span>.&quot;</span>)<br>    &#125;<br><br>    <span class="hljs-comment">// check the validity of the message by checking CRC</span><br>    <span class="hljs-comment">// 通过CRC 校验批次，如果不完整则抛异常</span><br>    <span class="hljs-keyword">if</span> (!batch.isValid) &#123;<br>      brokerTopicStats.allTopicsStats.invalidMessageCrcRecordsPerSec.mark()<br>      <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">CorruptRecordException</span>(<span class="hljs-string">s&quot;Record is corrupt (stored crc = <span class="hljs-subst">$&#123;batch.checksum()&#125;</span>) in topic partition <span class="hljs-subst">$topicPartition</span>.&quot;</span>)<br>    &#125;<br><br>    <span class="hljs-comment">// 更新最大时间戳以及对应的偏移量</span><br>    <span class="hljs-keyword">if</span> (batch.maxTimestamp &gt; maxTimestamp) &#123;<br>      maxTimestamp = batch.maxTimestamp<br>      offsetOfMaxTimestamp = lastOffset<br>    &#125;<br><br>    shallowMessageCount += <span class="hljs-number">1</span><br>    validBytesCount += batchSize<br><br>    <span class="hljs-comment">// 从消息批次中获取压缩器类型</span><br>    <span class="hljs-keyword">val</span> messageCodec = <span class="hljs-type">CompressionCodec</span>.getCompressionCodec(batch.compressionType.id)<br>    <span class="hljs-keyword">if</span> (messageCodec != <span class="hljs-type">NoCompressionCodec</span>)<br>      sourceCodec = messageCodec<br>  &#125;<br><br>  <span class="hljs-comment">// Apply broker-side compression if any</span><br>  <span class="hljs-comment">// 获取Broker端设置的压缩器类型，即Broker端参数compression.type值。</span><br>  <span class="hljs-comment">// 该参数默认值是producer，表示sourceCodec用的什么压缩器，targetCodec就用什么</span><br>  <span class="hljs-keyword">val</span> targetCodec = <span class="hljs-type">BrokerCompressionCodec</span>.getTargetCompressionCodec(config.compressionType, sourceCodec)<br>  <span class="hljs-keyword">val</span> lastLeaderEpochOpt: <span class="hljs-type">Option</span>[<span class="hljs-type">Int</span>] = <span class="hljs-keyword">if</span> (lastLeaderEpoch != <span class="hljs-type">RecordBatch</span>.<span class="hljs-type">NO_PARTITION_LEADER_EPOCH</span>)<br>    <span class="hljs-type">Some</span>(lastLeaderEpoch)<br>  <span class="hljs-keyword">else</span><br>    <span class="hljs-type">None</span><br>  <span class="hljs-comment">// 最后生成LogAppendInfo对象并返回</span><br>  <span class="hljs-type">LogAppendInfo</span>(firstOffset, lastOffset, lastLeaderEpochOpt, maxTimestamp, offsetOfMaxTimestamp, <span class="hljs-type">RecordBatch</span>.<span class="hljs-type">NO_TIMESTAMP</span>, logStartOffset,<br>    <span class="hljs-type">RecordConversionStats</span>.<span class="hljs-type">EMPTY</span>, sourceCodec, targetCodec, shallowMessageCount, validBytesCount, monotonic, lastOffsetOfFirstBatch)<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="读操作"><a href="#读操作" class="headerlink" title="读操作"></a>读操作</h3><p>下图是 read 方法的执行流程：</p>
<img src="/2022/08/31/Kafka%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-%E6%97%A5%E5%BF%97%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/modb_20211012_15f246f4-2b3f-11ec-94a3-fa163eb4f6be.png" srcset="/img/loading.gif" lazyload class="" title="img">

<p>read 方法的流程相对要简单一些：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><code class="hljs scala"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">read</span></span>(startOffset: <span class="hljs-type">Long</span>,<br>         maxLength: <span class="hljs-type">Int</span>,<br>         isolation: <span class="hljs-type">FetchIsolation</span>,<br>         minOneMessage: <span class="hljs-type">Boolean</span>): <span class="hljs-type">FetchDataInfo</span> = &#123;<br>  maybeHandleIOException(<span class="hljs-string">s&quot;Exception while reading from <span class="hljs-subst">$topicPartition</span> in dir <span class="hljs-subst">$&#123;dir.getParent&#125;</span>&quot;</span>) &#123;<br>    trace(<span class="hljs-string">s&quot;Reading maximum <span class="hljs-subst">$maxLength</span> bytes at offset <span class="hljs-subst">$startOffset</span> from log with &quot;</span> +<br>      <span class="hljs-string">s&quot;total length <span class="hljs-subst">$size</span> bytes&quot;</span>)<br><br>    <span class="hljs-keyword">val</span> includeAbortedTxns = isolation == <span class="hljs-type">FetchTxnCommitted</span><br><br>    <span class="hljs-comment">// Because we don&#x27;t use the lock for reading, the synchronization is a little bit tricky.</span><br>    <span class="hljs-comment">// We create the local variables to avoid race conditions with updates to the log.</span><br>    <span class="hljs-comment">// 步骤一：读取操作没有加锁，使用本地变量保存LEO对象，避免线程竞争</span><br>    <span class="hljs-keyword">val</span> endOffsetMetadata = nextOffsetMetadata<br>    <span class="hljs-keyword">val</span> endOffset = endOffsetMetadata.messageOffset<br>    <span class="hljs-comment">// 步骤二：找到startOffset值所对应的日志段</span><br>    <span class="hljs-keyword">var</span> segmentEntry = segments.floorEntry(startOffset)<br><br>    <span class="hljs-comment">// return error on attempt to read beyond the log end offset or read below log start offset</span><br>    <span class="hljs-comment">// 步骤三：判断消息是否越界</span><br>    <span class="hljs-comment">// 满足以下条件之一将被视为消息越界，即你要读取的消息不在该Log对象中:</span><br>    <span class="hljs-comment">// 1. 要读取的消息位移超过了LEO值</span><br>    <span class="hljs-comment">// 2. 没找到对应的日志段对象</span><br>    <span class="hljs-comment">// 3. 要读取的消息在Log Start Offset之下，同样是对外不可见的消息</span><br>    <span class="hljs-keyword">if</span> (startOffset &gt; endOffset || segmentEntry == <span class="hljs-literal">null</span> || startOffset &lt; logStartOffset)<br>      <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> <span class="hljs-type">OffsetOutOfRangeException</span>(<span class="hljs-string">s&quot;Received request for offset <span class="hljs-subst">$startOffset</span> for partition <span class="hljs-subst">$topicPartition</span>, &quot;</span> +<br>        <span class="hljs-string">s&quot;but we only have log segments in the range <span class="hljs-subst">$logStartOffset</span> to <span class="hljs-subst">$endOffset</span>.&quot;</span>)<br><br>    <span class="hljs-comment">// 查看一下读取隔离级别设置。</span><br>    <span class="hljs-comment">// 普通消费者能够看到[Log Start Offset, LEO)之间的消息</span><br>    <span class="hljs-comment">// 事务型消费者只能看到[Log Start Offset, Log Stable Offset]之间的消息。</span><br>    <span class="hljs-comment">// Follower副本消费者能够看到[Log Start Offset，高水位值]之间的消息</span><br>    <span class="hljs-keyword">val</span> maxOffsetMetadata = isolation <span class="hljs-keyword">match</span> &#123;<br>      <span class="hljs-keyword">case</span> <span class="hljs-type">FetchLogEnd</span> =&gt; endOffsetMetadata<br>      <span class="hljs-keyword">case</span> <span class="hljs-type">FetchHighWatermark</span> =&gt; fetchHighWatermarkMetadata<br>      <span class="hljs-keyword">case</span> <span class="hljs-type">FetchTxnCommitted</span> =&gt; fetchLastStableOffsetMetadata<br>    &#125;<br><br><br>    <span class="hljs-keyword">if</span> (startOffset == maxOffsetMetadata.messageOffset)<br>      emptyFetchDataInfo(maxOffsetMetadata, includeAbortedTxns)<br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (startOffset &gt; maxOffsetMetadata.messageOffset)<br>      <span class="hljs-comment">// 如果要读取的起始位置超过了能读取的最大位置，返回空的消息集合，因为没法读取任何消息</span><br>      emptyFetchDataInfo(convertToOffsetMetadataOrThrow(startOffset), includeAbortedTxns)<br>    <span class="hljs-keyword">else</span> &#123;<br>      <span class="hljs-comment">// Do the read on the segment with a base offset less than the target offset</span><br>      <span class="hljs-comment">// but if that segment doesn&#x27;t contain any messages with an offset greater than that</span><br>      <span class="hljs-comment">// continue to read from successive segments until we get some messages or we reach the end of the log</span><br>      <span class="hljs-comment">// 读取基本偏移量小于目标偏移量的日志段，但如果该段不包含任何偏移量大于该值的消息，继续从连续的段中读取</span><br>      <span class="hljs-keyword">var</span> done = segmentEntry == <span class="hljs-literal">null</span><br>      <span class="hljs-keyword">var</span> fetchDataInfo: <span class="hljs-type">FetchDataInfo</span> = <span class="hljs-literal">null</span><br>      <span class="hljs-keyword">while</span> (!done) &#123;<br>        <span class="hljs-keyword">val</span> segment = segmentEntry.getValue<br><br>        <span class="hljs-keyword">val</span> maxPosition =<br>          <span class="hljs-comment">// Use the max offset position if it is on this segment; otherwise, the segment size is the limit.</span><br>          <span class="hljs-keyword">if</span> (maxOffsetMetadata.segmentBaseOffset == segment.baseOffset) maxOffsetMetadata.relativePositionInSegment<br>          <span class="hljs-keyword">else</span> segment.size<br><br>        <span class="hljs-comment">// 步骤四：调用日志段对象的read方法执行真正的读取消息操作</span><br>        fetchDataInfo = segment.read(startOffset, maxLength, maxPosition, minOneMessage)<br>        <span class="hljs-keyword">if</span> (fetchDataInfo != <span class="hljs-literal">null</span>) &#123;<br>          <span class="hljs-keyword">if</span> (includeAbortedTxns)<br>            fetchDataInfo = addAbortedTransactions(startOffset, segmentEntry, fetchDataInfo)<br>        &#125; <span class="hljs-keyword">else</span> segmentEntry = segments.higherEntry(segmentEntry.getKey)<br><br>        done = fetchDataInfo != <span class="hljs-literal">null</span> || segmentEntry == <span class="hljs-literal">null</span><br>      &#125;<br><br>      <span class="hljs-comment">// 步骤五：封装结果并返回</span><br>      <span class="hljs-keyword">if</span> (fetchDataInfo != <span class="hljs-literal">null</span>) fetchDataInfo<br>      <span class="hljs-keyword">else</span> &#123;<br>        <span class="hljs-comment">// okay we are beyond the end of the last segment with no data fetched although the start offset is in range,</span><br>        <span class="hljs-comment">// this can happen when all messages with offset larger than start offsets have been deleted.</span><br>        <span class="hljs-comment">// In this case, we will return the empty set with log end offset metadata</span><br>        <span class="hljs-type">FetchDataInfo</span>(nextOffsetMetadata, <span class="hljs-type">MemoryRecords</span>.<span class="hljs-type">EMPTY</span>)<br>      &#125;<br>    &#125;<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p>它接收 4 个参数，含义如下：</p>
<ul>
<li><p>startOffset，即从 Log 对象的哪个位移值开始读消息。</p>
</li>
<li><p>maxLength，即最多能读取多少字节。</p>
</li>
<li><p>isolation，设置读取隔离级别，主要控制能够读取的最大位移值，多用于 Kafka 事务。</p>
</li>
<li><p>minOneMessage，即是否允许至少读一条消息。设想如果消息很大，超过了maxLength，正常情况下 read 方法永远不会返回任何消息。但如果设置了该参数为true，read 方法就保证至少能够返回一条消息。</p>
</li>
</ul>
<p>read 方法的返回值是 FetchDataInfo 类，也是一个 POJO 类，里面最重要的数据就是读取的消息集合，其他数据还包括位移等元数据信息。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>日志对象的常见操作主要包含四部分：高水位管理、日志段管理、关键位移管理、读写操作。</strong></p>
<p><strong>高水位管理：高水位值也属于关键位移，只不过高水位更加重要，因此单独拿出来讲</strong>。</p>
<p><strong>日志段管理：作为日志段的容器，Log 对象保存了很多日志段对象，操作 Log 对象的同时，也会操作到对应日志段。</strong></p>
<p><strong>关键位移管理：除了高水位值以外，还有对 Log Start Offset 和 LEO 的管理。这两个位移值是 Log对象非常关键的字段。比如，副本管理、状态机管理等高阶功能都要依赖于它们。</strong></p>
<p><strong>读写操作：</strong></p>
<p><strong>日志对象的写数据操作分为十二个步骤：</strong></p>
<ul>
<li><strong>校验消息</strong></li>
<li><strong>调整待写入消息集合的大小</strong></li>
<li><strong>分配偏移量</strong></li>
<li><strong>验证批次大小是否超过限制</strong></li>
<li><strong>更新leader epoch 缓存</strong></li>
<li><strong>确保待写入消息集合大小不超过1个日志段容量</strong></li>
<li><strong>验证事务状态</strong></li>
<li><strong>判断是否需要进行日志滚动</strong></li>
<li><strong>调用日志段的append方法写入数据</strong></li>
<li><strong>更新LEO对象</strong></li>
<li><strong>更新事务状态</strong></li>
<li><strong>返回写入结果</strong></li>
</ul>
<p><strong>日志对象的读数据操作分为五个步骤：</strong></p>
<ul>
<li><strong>从LEO对象中获取LEO值</strong></li>
<li><strong>找到读取的起始偏移量对应的日志段</strong></li>
<li><strong>判断要读取的消息是否越界</strong></li>
<li><strong>遍历包含要读取消息的日志段，调用日志段的read方法进行数据读取</strong></li>
<li><strong>返回读取结果</strong></li>
</ul>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/Kafka/">Kafka</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/Kafka/">Kafka</a>
                    
                      <a class="hover-with-bg" href="/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/">消息队列</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/09/02/Kafka%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-%E7%B4%A2%E5%BC%95%E6%96%87%E4%BB%B6%E5%8F%8A%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Kafka源码解析-索引文件及内存映射</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/08/30/Kafka%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-%E6%97%A5%E5%BF%97%E5%AF%B9%E8%B1%A1%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B5%81%E7%A8%8B/">
                        <span class="hidden-mobile">Kafka源码解析-日志对象初始化流程</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  

  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js" ></script>



  <script  src="/js/local-search.js" ></script>






  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>















<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
